{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### uncomment to display figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrates benchmarking functionality - SASMAS Soil Moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmarking dataset information\n",
    "The soil moisture content (in mm) dataset consists of time-series of soil water content reflectometer measurements at various depths within the profile (top:0-5cm, shallow:0-30cm, middle:30-60cm, deep:60-90cm) within the Upper Hunter River\n",
    "<br>\n",
    "##### Source:\n",
    "RÃ¼diger, C., Hancock, G., Hemakumara, H.M., Jacobs, B., Kalma, J.D., Martinez, C., Thyer, M., Walker, J.P., Wells, T. and Willgoose, G.R., 2007. Goulburn River experimental catchment data set. Water Resources Research, 43(10): W10403."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through the following steps:\n",
    "\n",
    "1. Import required libraries\n",
    "2. Set up benchmarking configuration <br>\n",
    " 2.1 Catchments to be benchmarked<br>\n",
    " 2.2 Define observation inputs<br>\n",
    "\n",
    "3. Create benchmark object<br>\n",
    "4. Add models to be benchmarked <br>\n",
    " 4.1 Select or unselect models<br> \n",
    "5. View benchmarking statistics<br>\n",
    "6. View benchmarking plots<br>\n",
    "7. Statistics plotting<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from awrams.benchmarking.benchmark import BenchmarkSoilMoisture\n",
    "from awrams.utils import datetools as dt\n",
    "import awrams.benchmarking.config as cfg\n",
    "import awrams.benchmarking.meta.sasmas as sasmas\n",
    "\n",
    "from awrams.models.settings import TRAINING_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Set up benchmarking configuration\n",
    "Comparison against observed streamflow <br>\n",
    "You can use your own data in csv form similar to the example provided. <br>\n",
    "It just needs to have column names matching the names used in extracting AWRA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Sites to be benchmarked\n",
    "Soil moisture comparisons at SASMAS sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sasmas_data_path = TRAINING_DATA_PATH + '/benchmarking/sasmas/' #  # the sasmas data has been pre-processed into 5 files [top, shallow, middle, deep, profile]\n",
    "\n",
    "site_list = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'K1', 'K2', 'K3', 'K4', 'K5', 'K6', 'M1', 'M2', 'M3', \n",
    "             'M4', 'M5', 'M6', 'M7', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7']\n",
    "\n",
    "mod_site_list = ['SASMAS Soil moisture_' + site for site in site_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create the benchmark object:<br> \n",
    "\n",
    "An object of \"Benchmark\" class is created by defining what variable is to be benchmarked. \n",
    "Everything else gets progressively added,  and statistics are calculated when the observation and model outputs are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas = BenchmarkSoilMoisture(\"SASMAS\", \"soil moisture\", sasmas.meta)\n",
    "\n",
    "# Specify benchmarking period\n",
    "sas.period = dt.dates('2003-2011')\n",
    "\n",
    "# Add observations and catchment subset [the id list needs to be present in the column names of the observation file]\n",
    "sas.load(sasmas_data_path,mod_site_list,convert_units=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G1',\n",
       " 'G2',\n",
       " 'G3',\n",
       " 'G4',\n",
       " 'G5',\n",
       " 'G6',\n",
       " 'K1',\n",
       " 'K2',\n",
       " 'K3',\n",
       " 'K4',\n",
       " 'K5',\n",
       " 'K6',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'S1',\n",
       " 'S2',\n",
       " 'S3',\n",
       " 'S4',\n",
       " 'S5',\n",
       " 'S6',\n",
       " 'S7']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sas.sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg.MONTHLY_REJECTION_THRESHOLD = 15 # Minimum number of available obs days before monthly stats are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s0_avg', 'ss_avg', 'sd_avg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.SM_MODEL_VARNAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s0_avg': 100.0, 'sd_avg': 5000.0, 'ss_avg': 900.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.SM_MODEL_LAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Add models to be benchmarked\n",
    "Any number of models can be simulataneously compared\n",
    "This step processes the data and calculates all the statistics [can take a while]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = sasmas_data_path+\"/awral_${v}.csv\"\n",
    "sas.add_model(\"AWRAMSI.v4_0.AWRAL\", csv_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = sasmas_data_path+\"/AWRAMSI_v5QES_AWRAL_SASMAS_${v}.csv\" \n",
    "sas.add_model(\"AWRAMSI.v5_0.AWRAL\", csv_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Show list of loaded or selected models\n",
    "list of loaded models is available with <tab> activated dropdown by typing \"et.models.\"<br>\n",
    "can \"select\" or \"unselect\" models for displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas.benchmark.top.selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. View benchmarking statistics\n",
    "Summary percentiles can be printed out by specifying a statistic from: <br> \n",
    "\"grand_f\", \"nse\", \"bias_relative\", \"pearsons_r\" (default), \"mean\"  <br>\n",
    "to the 'stat_percentiles' function<br>\n",
    "The timeframe defaults to monthly, but can be specified\n",
    "\n",
    "These tables are pandas dataframes, so they can be exported to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas.benchmark.deep.stat_percentiles('fobj',freq='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas.benchmark.deep.stat_percentiles('grand_f',freq='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas.benchmark.top.stat_percentiles('bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas.benchmark.shallow.stat_percentiles('nse','daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas.benchmark.shallow.data_percentiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. View benchmarking plots [time series, Regression]\n",
    "\n",
    "specify frequency by \"freq=d\" for daily, \"freq=m\" for monthly, \"freq=y\" for yearly<br>\n",
    "can customise titles, labels, scaling etc using standard matplotlib keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sas.benchmark.top.selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.shallow.plot_timeseries('G1','raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.top.plot_timeseries('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.shallow.plot_timeseries('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.middle.plot_timeseries('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.deep.plot_timeseries('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.profile.plot_timeseries('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.shallow.plot_regression('M1',xlim=[-1,60],ylim=[-1,60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Statistics plotting\n",
    "specify statistic type from \"fobj\", \"nse\", \"rmse\", \"bias_relative\", \"pearsons_r\" (default), \"mean\" and <br> frequency from 'd', 'm', 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.shallow.plot_box('pearsons_r','daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.shallow.plot_cdf('pearsons_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sas.benchmark.shallow.plot_box('nse','daily',ylim=[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
